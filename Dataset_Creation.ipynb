{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIqg187CR4zcJ7hp9lp5ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buddika-Kasun/ML/blob/main/Dataset_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üìò SLSL Sentence-Based Dataset Landmark Extraction Pipeline\n",
        "# Uses MediaPipe Holistic to extract hand, pose, and lip landmarks\n",
        "# Dataset is structured in Google Drive by sentence folders\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "ReKkbncHkzMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Install Dependencies ---\n",
        "!pip install mediapipe opencv-python pandas numpy tqdm\n",
        "!apt update && apt install -y ffmpeg\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "p0UOJwswlPfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üìÅ 1. Folder Setup\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "Jnj3pLXhlVIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentence_based_structure():\n",
        "    \"\"\"Create necessary folders in Colab workspace\"\"\"\n",
        "    os.makedirs('/content/raw_videos', exist_ok=True)\n",
        "    os.makedirs('/content/landmarks_data', exist_ok=True)\n",
        "    os.makedirs('/content/metadata', exist_ok=True)\n",
        "    print(\"‚úÖ Folder structure ready!\")\n",
        "    print(\"üìÅ /content/raw_videos ‚Äì for input videos\")\n",
        "    print(\"üìÅ /content/landmarks_data ‚Äì for output .npy files\")\n",
        "    print(\"üìÅ /content/metadata ‚Äì for metadata and mapping files\")"
      ],
      "metadata": {
        "id": "5XBv5Pa8li9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üìÇ 2. Copy Dataset from Google Drive\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "0rNBvzRal2jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_from_drive(drive_path='/content/drive/MyDrive/SLSL_Dataset'):\n",
        "    \"\"\"\n",
        "    Copy your structured folder from Google Drive into Colab.\n",
        "    Your Drive should have:\n",
        "      MyDrive/SLSL_Dataset/\n",
        "        ‚îú‚îÄ‚îÄ where_does_it_hurt/\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ signer_01_rep_1.mp4\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "        ‚îú‚îÄ‚îÄ i_have_a_headache/\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ signer_02_rep_1.mp4\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "    \"\"\"\n",
        "\n",
        "    if os.path.exists(drive_path):\n",
        "        shutil.copytree(drive_path, '/content/raw_videos', dirs_exist_ok=True)\n",
        "        print(\"‚úÖ Copied entire structure from Google Drive!\")\n",
        "        sentences = os.listdir('/content/raw_videos')\n",
        "        print(f\"üìÅ Sentence folders copied: {len(sentences)}\")\n",
        "        for sentence in sentences:\n",
        "            sentence_path = f\"/content/raw_videos/{sentence}\"\n",
        "            video_count = len([f for f in os.listdir(sentence_path) if f.endswith('.mp4')])\n",
        "            print(f\"   {sentence}: {video_count} videos\")\n",
        "    else:\n",
        "        print(f\"‚ùå Folder not found in Google Drive at: {drive_path}\")\n",
        "        print(\"üí° Please check the folder path and name.\")"
      ],
      "metadata": {
        "id": "rmeJl2DSl8n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üß† 3. Setup MediaPipe Holistic\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "T7ssJTbOmCXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_holistic = mp.solutions.holistic\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "def setup_mediapipe():\n",
        "    \"\"\"Setup MediaPipe Holistic with balanced accuracy/speed\"\"\"\n",
        "    holistic = mp_holistic.Holistic(\n",
        "        static_image_mode=False,\n",
        "        model_complexity=1,\n",
        "        smooth_landmarks=True,\n",
        "        enable_segmentation=False,\n",
        "        refine_face_landmarks=True,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5\n",
        "    )\n",
        "    return holistic"
      ],
      "metadata": {
        "id": "eJJ5JAwpmIHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üéØ 4. Extract Landmarks from Frame\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "fQguMkvkmNdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frame_landmarks(frame, holistic_model):\n",
        "    \"\"\"Extract hand, pose, and lip landmarks from one frame\"\"\"\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame_rgb.flags.writeable = False\n",
        "    results = holistic_model.process(frame_rgb)\n",
        "\n",
        "    landmarks_dict = {\n",
        "        'left_hand': None,\n",
        "        'right_hand': None,\n",
        "        'pose': None,\n",
        "        'face': None,\n",
        "        'lip_roi': None,\n",
        "        'timestamp': None\n",
        "    }\n",
        "\n",
        "    # --- Left Hand ---\n",
        "    if results.left_hand_landmarks:\n",
        "        left_hand = []\n",
        "        for landmark in results.left_hand_landmarks.landmark:\n",
        "            left_hand.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "        landmarks_dict['left_hand'] = left_hand\n",
        "\n",
        "    # --- Right Hand ---\n",
        "    if results.right_hand_landmarks:\n",
        "        right_hand = []\n",
        "        for landmark in results.right_hand_landmarks.landmark:\n",
        "            right_hand.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "        landmarks_dict['right_hand'] = right_hand\n",
        "\n",
        "    # --- Pose (upper body) ---\n",
        "    if results.pose_landmarks:\n",
        "        pose = []\n",
        "        upper_body_indices = list(range(25))\n",
        "        for i in upper_body_indices:\n",
        "            landmark = results.pose_landmarks.landmark[i]\n",
        "            pose.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "        landmarks_dict['pose'] = pose\n",
        "\n",
        "    # --- Lips from Face Mesh ---\n",
        "    if results.face_landmarks:\n",
        "        lip_indices = [\n",
        "            61, 84, 314, 17, 87, 178, 88, 95, 78, 62, 96, 89,\n",
        "            146, 91, 181, 76, 184, 74, 183, 42, 13, 82, 81, 80,\n",
        "            191, 78, 312, 311, 310, 415, 308, 324, 318, 402,\n",
        "            317, 14, 87, 178\n",
        "        ]\n",
        "        lip_landmarks = []\n",
        "        face_landmarks = []\n",
        "        for i, landmark in enumerate(results.face_landmarks.landmark):\n",
        "            face_landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "            if i in lip_indices:\n",
        "                lip_landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "        landmarks_dict['face'] = face_landmarks\n",
        "        landmarks_dict['lip_roi'] = lip_landmarks\n",
        "\n",
        "    return landmarks_dict"
      ],
      "metadata": {
        "id": "mBblMukvmTvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üéûÔ∏è 5. Process a Single Video\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "6zdjpF7kmZYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_single_video(video_path, holistic_model, max_frames=None):\n",
        "    \"\"\"Process one video and extract landmarks frame by frame\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames_data = []\n",
        "    frame_count = 0\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"\\nüìπ Processing: {os.path.basename(video_path)} ({total_frames} frames)\")\n",
        "\n",
        "    with tqdm(total=total_frames, desc=\"Extracting landmarks\") as pbar:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if max_frames and frame_count >= max_frames:\n",
        "                break\n",
        "\n",
        "            landmarks = extract_frame_landmarks(frame, holistic_model)\n",
        "            landmarks['timestamp'] = frame_count / fps\n",
        "            frames_data.append(landmarks)\n",
        "            frame_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"‚úÖ Extracted {len(frames_data)} frames.\")\n",
        "    return frames_data"
      ],
      "metadata": {
        "id": "aM0tK58wmfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üß© 6. Process Entire Dataset (Sentence-based)\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "9pLyeloMmjL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sentence_based_dataset(raw_videos_root='/content/raw_videos',\n",
        "                                   output_folder='/content/landmarks_data',\n",
        "                                   test_mode=False):\n",
        "    \"\"\"Process all sentence folders in dataset\"\"\"\n",
        "    metadata = []\n",
        "\n",
        "    print(\"üîç Scanning for sentence folders...\")\n",
        "    sentence_folders = [f for f in os.listdir(raw_videos_root)\n",
        "                        if os.path.isdir(os.path.join(raw_videos_root, f))]\n",
        "    print(f\"üìÅ Found {len(sentence_folders)} sentences.\")\n",
        "\n",
        "    for sentence in sentence_folders:\n",
        "        sentence_path = os.path.join(raw_videos_root, sentence)\n",
        "        video_files = [f for f in os.listdir(sentence_path)\n",
        "                       if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "\n",
        "        print(f\"\\nüé¨ Sentence: {sentence} ‚Äì {len(video_files)} videos\")\n",
        "        if test_mode:\n",
        "            video_files = video_files[:1]\n",
        "            print(\"‚öôÔ∏è TEST MODE: Only 1 video processed per sentence\")\n",
        "\n",
        "        for video_file in video_files:\n",
        "            video_path = os.path.join(sentence_path, video_file)\n",
        "            filename_parts = video_file.replace('.mp4', '').split('_')\n",
        "            signer_id = filename_parts[1] if len(filename_parts) > 1 else \"unknown\"\n",
        "            rep_number = filename_parts[3] if len(filename_parts) > 3 else \"1\"\n",
        "\n",
        "            try:\n",
        "                landmarks_seq = process_single_video(video_path, holistic,\n",
        "                                                     max_frames=50 if test_mode else None)\n",
        "                if landmarks_seq:\n",
        "                    output_filename = f\"{sentence}_signer_{signer_id}_rep_{rep_number}.npy\"\n",
        "                    output_path = os.path.join(output_folder, output_filename)\n",
        "                    np.save(output_path, landmarks_seq)\n",
        "\n",
        "                    left_hand_frames = sum(1 for f in landmarks_seq if f['left_hand'])\n",
        "                    right_hand_frames = sum(1 for f in landmarks_seq if f['right_hand'])\n",
        "                    lip_frames = sum(1 for f in landmarks_seq if f['lip_roi'])\n",
        "\n",
        "                    metadata.append({\n",
        "                        'landmarks_file': output_filename,\n",
        "                        'sentence': sentence,\n",
        "                        'signer_id': signer_id,\n",
        "                        'rep_number': rep_number,\n",
        "                        'original_video': video_file,\n",
        "                        'video_path': video_path,\n",
        "                        'total_frames': len(landmarks_seq),\n",
        "                        'left_hand_frames': left_hand_frames,\n",
        "                        'right_hand_frames': right_hand_frames,\n",
        "                        'lip_frames': lip_frames,\n",
        "                        'left_hand_coverage': (left_hand_frames / len(landmarks_seq)) * 100,\n",
        "                        'right_hand_coverage': (right_hand_frames / len(landmarks_seq)) * 100,\n",
        "                        'lip_coverage': (lip_frames / len(landmarks_seq)) * 100,\n",
        "                        'success': True\n",
        "                    })\n",
        "                    print(f\"üíæ Saved landmarks ‚Üí {output_filename}\")\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è No landmarks extracted in {video_file}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error processing {video_file}: {str(e)}\")\n",
        "                metadata.append({\n",
        "                    'landmarks_file': 'FAILED',\n",
        "                    'sentence': sentence,\n",
        "                    'signer_id': signer_id,\n",
        "                    'rep_number': rep_number,\n",
        "                    'original_video': video_file,\n",
        "                    'error': str(e),\n",
        "                    'success': False\n",
        "                })\n",
        "\n",
        "    # Save metadata\n",
        "    if metadata:\n",
        "        metadata_df = pd.DataFrame(metadata)\n",
        "        meta_csv = '/content/metadata/sentence_dataset_metadata.csv'\n",
        "        metadata_df.to_csv(meta_csv, index=False)\n",
        "\n",
        "        sentence_mapping = {s: i for i, s in enumerate(metadata_df['sentence'].unique())}\n",
        "        with open('/content/metadata/sentence_mapping.json', 'w') as f:\n",
        "            json.dump(sentence_mapping, f, indent=2)\n",
        "\n",
        "        print(f\"\\nüìä Metadata saved ‚Üí {meta_csv}\")\n",
        "        return metadata_df, sentence_mapping\n",
        "    else:\n",
        "        print(\"‚ùå No videos processed successfully!\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "Eyc5-_kJmqQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üìà 7. Dataset Analysis\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "NfnaRiRUmuUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentence_dataset(metadata_df):\n",
        "    \"\"\"Print statistics about processed dataset\"\"\"\n",
        "    print(\"\\nüìä SENTENCE DATASET ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    total = len(metadata_df)\n",
        "    success = metadata_df['success'].sum()\n",
        "    print(f\"Videos processed: {total}, Success: {success} ({success/total*100:.1f}%)\")\n",
        "\n",
        "    sentence_stats = metadata_df[metadata_df['success']]['sentence'].value_counts()\n",
        "    print(\"\\nüìù Videos per sentence:\")\n",
        "    for s, c in sentence_stats.items():\n",
        "        print(f\"   {s}: {c}\")\n",
        "\n",
        "    signer_stats = metadata_df[metadata_df['success']]['signer_id'].value_counts()\n",
        "    print(\"\\nüë• Videos per signer:\")\n",
        "    for s, c in signer_stats.items():\n",
        "        print(f\"   Signer {s}: {c}\")"
      ],
      "metadata": {
        "id": "iHPyrYfAm4ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üîç 8. Verify Landmark Files\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "GCygoUwqnDHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_landmark_files(folder='/content/landmarks_data'):\n",
        "    \"\"\"Check a few saved .npy files\"\"\"\n",
        "    print(\"\\nüîç Verifying sample landmark files...\")\n",
        "    files = [f for f in os.listdir(folder) if f.endswith('.npy')]\n",
        "    print(f\"Found {len(files)} landmark files.\")\n",
        "\n",
        "    for file in files[:3]:\n",
        "        data = np.load(os.path.join(folder, file), allow_pickle=True)\n",
        "        print(f\"\\nüìÑ {file} ‚Äì {len(data)} frames\")\n",
        "        if len(data) > 0:\n",
        "            print(\"Keys:\", list(data[0].keys()))"
      ],
      "metadata": {
        "id": "vkmJeArInG3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# üöÄ 9. Main Pipeline\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "DxKSB-tgnL8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_pipeline(test_mode=True):\n",
        "    print(\"üöÄ STARTING SLSL SENTENCE-BASED DATASET PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Folder setup\n",
        "    create_sentence_based_structure()\n",
        "\n",
        "    # Step 2: Copy dataset from Google Drive\n",
        "    copy_from_drive(drive_path='/content/drive/MyDrive/SLSL_Dataset') # ‚úÖ adjust path if needed\n",
        "\n",
        "    # Step 3: Initialize MediaPipe\n",
        "    global holistic\n",
        "    holistic = setup_mediapipe()\n",
        "    print(\"‚úÖ MediaPipe Holistic initialized\")\n",
        "\n",
        "    # Step 4: Process dataset\n",
        "    metadata_df, sentence_mapping = process_sentence_based_dataset(test_mode=test_mode)\n",
        "\n",
        "    # Step 5: Analyze and verify\n",
        "    if metadata_df is not None:\n",
        "        analyze_sentence_dataset(metadata_df)\n",
        "        verify_landmark_files()\n",
        "        print(\"\\nüéâ Dataset processing complete!\")\n",
        "        return metadata_df, sentence_mapping\n",
        "    else:\n",
        "        print(\"‚ùå Dataset creation failed.\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "ceWI2HfFnRB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# ‚ñ∂Ô∏è 10. Run Pipeline\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "85AiEBkKnV1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata, mapping = main_pipeline(test_mode=True)\n",
        "# When ready for full run, set test_mode=False\n",
        "# metadata, mapping = main_pipeline(test_mode=False)"
      ],
      "metadata": {
        "id": "syCrvdsynfky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}